# Data Analysis of 4 combination Operator

This work analyzes the use of four combination operators of forecasting tasks: simple mean, median, SVR-stacking and weighted average by feature importance.

## Data

To do this project 30 time series with monthly seasonality were selected from M3 Competition's Dataset. As the competition itself, the monthly series have to be splitted into training and testing sets, in latter is composed by the last 18 observatio.

## Models

There were choose 9 methods to be combined, 5 statiscal methods and 4 machine learning (ML) ones. The statistical one are: ARIMA, ETS, Theta, CES, and TBATS. ML ones: MLP, SVR, Random Forest and KNN.

## System

### General

The way to carry out the project is a system that loads the data, splits each loaded series into two sets, training and test; trains the models with training set; and combines them by all 4 operator. After that, the models and their combination are tested on testing set. The results are evaluated by RMSE and SMAPE metrics.

### Combinations

A essential detail about how the combination are evaluated is the number of methods which are ensembled. For each operator all method are combined into a ensemble composed from 2 model until 9, without repetition, *i.e*, is a mathmatical combination, not a permutation.

### Weighted Mean

The fourth operator, weighted average, has a innovative manner of estimate the weigths: features importance (FI).There are some  is a technique --- generally used with tree-based models --- which assigns value to features by ["as the (normalized) total reduction of the criterion brought by that feature. It is also known as the Gini importance."](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesRegressor.html#sklearn.ensemble.ExtraTreesRegressor.feature_importances_), in this case, the criterion is the MSE, because it is regresssion problem.

The model choose to estimate the FI weights is Extremely Randomized Trees, also known as Extra Trees. There are some advantages in applying it: it is faster than models likes Random Forest or Gradient Boosting Machine, it can cope with noisy data --- time series has noise as internal feature --- and has lower variance when compared to other models like Random Forest.

### Errors

The error values generated by testing were placed in two .csv files: "monthly_model_sensitivity_rmse_results.csv" and "monthly_model_sensitivity_smapr_results.csv".

## Data Analysis

After the csv files been created, the data analysis were made from them. The information, chats and tables, of error values are in the Quarto file relatorio.html and in the article.